<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
	<script src="https://cdnjs.cloudflare.com/ajax/libs/jsrsasign/8.0.4/jsrsasign-all-min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/load-svg-file/dist/load-svg-file.js"></script>
	<script src="https://apis.google.com/js/api.js"></script>
	<style>
 --iris: 200px;

body {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
}
#eye {
  position: relative;
  svg {
    width: var(--iris);
    height: vsar(--iris);
    #upper-eye-lid-cover {
      fill: #fff;
    }
  }
}  

 #face {
        width: 100%;
        height: 100%;
        position: relative;
      }
 #upperFace {
        width: 100%;
        height: 100%;
        position: absolute;
        top: 0;
        left: 0;
        opacity: 0.9;
		z-index: 33;
      }	 
 #lowerFace {
        z-index: 9;
		opacity: 0.9;
		transform: scale(1,1);
      }  
	  



.duration-750 {
animation-duration: 750ms;}

.infinite {
  animation-iteration-count: infinite; }

.animation-count-3 {
  animation-duration: 500ms; }
  animation-iteration-count: 3;}

.animation-stop {
  animation-iteration-count: 0;}






.movingLips {
   	d: path('m 72,90 q 15 -2, 25 0 q 3 2, 6 0 q 10 -2, 25 0 q -28 10, -56 0');  
  animation: lipsPath 0.6s linear 12;
}

@keyframes lipsPath {
  0% {
     d: path('m 72,90 q 15 -2, 25 0 q 3 2, 6 0 q 10 -2, 25 0 q -28 10, -56 0');
  }
 
  25% {
     d: path('m 70,90 q 15 -12, 27 -8 q 3 2, 6 0 q 10 -4, 27 8 q -30 10, -60 0');
  }
 
  75% {
    d: path('m 72,90 q 15 -2, 25 2 q 3 2, 6 0 q 10 -4, 25 -2 q -28 10, -56 0');  
  }
}


@keyframes lipsPath2 {
  25% {
     d: path('m 70,90 q 15 -12, 27 -8 q 3 2, 6 0 q 10 -4, 27 8 q -30 10, -60 0');
  }

  0% {
	 d: path('m 75,90 q 15 -2, 24 3 q 2 2, 4 0 q 10 -2, 24 -3 q -27 10, -54 0');    
  } 

  0% {
     d: path('m 72,90 q 15 -2, 25 0 q 3 2, 6 0 q 10 -2, 25 0 q -25 10, -56 0');
  }

  25% {
     d: path('m 70,90 q 15 -12, 27 -8 q 3 2, 6 0 q 10 -4, 27 8 q -30 10, -60 0');
  }
  
  75% {
	 d: path('m 74,90 q 15 -2, 25 2 q 2 2, 4 0 q 10 -4, 25 -2 q -25 10, -52 0');    
  } 
}

 d: path('m 70,90 q 15 -2, 27 0 q 3 2, 6 0 q 10 -2, 27 0 q -30 10, -60 0'); 
 
  d: path('m 70,90 q 15 -2, 27 2 q 3 2, 6 0 q 10 -4, 27 -2 q -30 10, -60 0'); 
 
</style>
    <title>speech recognition and query</title>
  </head>
  <body>
    <header>
      <h1>Browser speech recognition and talking</h1>
    </header>
<div id = "face" >
<div id = "upperFace"  >
</div>
<div id = "lowerFace" >
 <svg xmlns="http://www.w3.org/2000/svg"
  xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 200 200">
    <defs>
    <filter id="blur" x="0" y="0">
      <feGaussianBlur in="SourceGraphic" stdDeviation="15" />
    </filter>
	<filter id="blur2" x="0" y="0">
      <feGaussianBlur in="SourceGraphic" stdDeviation="1" />
    </filter>
	  </defs>
	 <defs>
      <radialGradient id="faceColor" fx="50%" fy="95%" >
        <stop offset="0%" stop-color="rgba(165, 99, 66, 0.6)" />
        <stop offset="100%" stop-color="rgba(55, 33, 22, 0.6)" />
		</radialGradient>
		</defs>
		
	<defs>
      <radialGradient  id="lipColor" fx="50%" fy="5%" >
        <stop offset="0%" stop-color="rgba(255, 102, 204, 0.6)" />
        <stop offset="35%" stop-color="rgba(127, 51, 102, 0.6)" />
        <stop offset="100%" stop-color="rgba(63, 26, 51, 0.6)" /> 
		</radialGradient>
		</defs>
		
    <g>
	 <g id="middleFace">
     <path d="m 70,90 q 30 10, 60 0 l 20 -10 q 70 -50, 0 -75 q -10 -3, -40 10 q -10 3 , -20 0 q -30 -13,-40 -10 q -70 25,0 75 l 20 10 z" 
	 stroke-width="15" fill="url(#faceColor)" filter="url(#blur)" />
	  </g>
	  <g id="lips">
      <path id="lipsPath" d="m 70,90 q 15 -2, 27 0 q 3 2, 6 0 q 10 -2, 27 0 q -30 10, -60 0" fill ="url(#lipColor)" />
	  </g>
	</g>
	  </svg>
</div>
</div>

    <div>
      <button id="button">Start listening</button>
      <div id="result"></div>
      <p id="message" hidden aria-hidden="true">
        Your browser doesn't support Speech Recognition. Sorry.
      </p>
	  <p id="inputText">    </p>
    </div>

    <script>
// This works well!
//===================== get token:
	let private_key_id = "7dc203a2253c7fa8fee2af8e710df4cc4b424e24";
	let private_key = "-----BEGIN PRIVATE KEY-----\nMIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQCzNXAINaHc8vKO\nAFvooGRSPxIFBTwMwaY4E4E//ZWVnydptyLIh26CsDYAC5fy2xfA8k3OWlf+qjmb\nGgX4ej2jGh6FIPJgV+BnQ/iDMjfPjX06eMwHJApTYvJ9PoUAab8l73dHX88LSO8y\nVN9UBY0+j6pCmgxgolt/iZutIDPME7uDmXJYKVzjdcz5SVgFr4Kd+flwO6l+wWNU\nK/0SViprhmPe5ZRjq6eIzVGqna/sL3Jk7fFaVAHgtzQmJG8HXeIFtHDoqUz0JdHk\n9qmeheNxCiTv/RV55H+O1P8IEtMbXvMPxQJXN7vUslU5qS1yqR5xCb8aAOUkO5ic\nGNDQWgHtAgMBAAECggEAGTpqnR0/viUNdGQkjCkYNmPem4pTG9CfH8HPLjz6s+eF\n2uIHKYe3TPqVf4giSfQB8g2qWmRpgtZf6a/OK166Ep34sfEjbeCxHJh7Aa0uIi/e\n8z5SKqcuNPL3BB6rBpXcbPC7L/cS5JnN4p4EGoX1jlsXMu0Q1QHGM7whiEvCPvZD\noZ2Td5qPTC6f0JeoTJXMaacaZorgYE/m/pqcstDiXwcIHT585krKgjiwJTVM81LS\nW7DO4tWDwndQUvQtzJ+klW6ySl8EmopKlhu8tP7nbo2EVSRpSQenzT9+ZjIVXWAX\nzq0ouN776Z+gB4eR/OjOETOgw5SNduKWkVJfLaOMAQKBgQDqL1Qw6VwL4IVpon1K\n85n81LFOBh+RvzbIOUH0Etd8T69PVibjbJySXrKdSvntSBcaKEAjLb7NTzmYqNbS\nUN8lC7XI58NZ39Aj5jgGd7XkyY0qBDHVjd/wgqQPHALWfZOvzE5933vLVrnbXjB/\n98ZgcXIeJE1zaInsniqBCbQRbQKBgQDD5xPj4/OxuCIq3dT2CIlCGOCretV6KflI\nZyz7XK7fZByVjZyc9xFHv4UibHl37Uy9uUoCPRv8r19zlLVP4pLnrZj/GgBWmEcb\nzy0bHLkeaaPbmnj+Zb+cSTM46DhJ4YNrQRr3gjsc7U6dSWs0p0KON3wMa7P4YWbS\n5YrZoEfigQKBgQCzycYvDtk13RdPtAnQ4xhTfM7qgdT2xgA+04aI5XY938dNd2y/\nqQDDdqRWEduyiWgDEue6mkIjyTEEvIrASIooHMdhCF13wFZBWVuly33/uaUAntvL\ngfJs6T8ewniDR0F887NG+65Eu75QZg2CES1hmXbtIR28/oL0/7DOBC8UOQKBgQCC\nK5po1AAKt/pkF3C5ZuSledhXuU/+U8Ojm4MlJum/4EqqCSXmmrjtvtHdFM0FpjVW\n37bQlABzv6giKc7sXPYWYaCG6aUN5TNixCAJouVS0wkhE5yQFdXjKDST/KHiXamw\na9taWTukNf8FvlIw827jBvUzX6F/SmFDg2jmwHzjgQKBgQDmT6bnYDu3d8oB7qtK\ny2sFtqKLDNbIr0seqpRCM3JKGo8vLaFifm9v6GpSd/DtISX1sqEQr5wTMW2wDNa9\n34d153FMp483Gs5j/f9hew9xEOI9axsAxXlirm+n3G8D8VRh1rW0OuW1D9pc9iMX\ntS3Lilhd/vj9HOoezREl7rrFhQ==\n-----END PRIVATE KEY-----\n";
	let client_email = "megan1@megaagent-9goq.iam.gserviceaccount.com";
	const header = {
        alg: 'RS256',
        typ: 'JWT',
        kid: private_key_id  ////???
      }

      // Payload
      const payload = {
        iss: client_email,
        sub: client_email,
        iat: KJUR.jws.IntDate.get('now'),
        exp: KJUR.jws.IntDate.get('now + 1hour'),
        aud: 'https://dialogflow.googleapis.com/google.cloud.dialogflow.v2.Sessions'	
      }
      
      const stringHeader = JSON.stringify(header);
      const stringPayload = JSON.stringify(payload);
      var token = KJUR.jws.JWS.sign('RS256', stringHeader, stringPayload, private_key);
	
	console.log("token: " + token);
//====== Got token for Dialogflow service  
var base_url = 'https://dialogflow.googleapis.com/v2/projects/mymega-hc9x/agent/sessions';
var languageCode = 'en-US';
 async function queryDialog(input_data){
 console.log("input_data2:" + input_data )
  const response = await fetch(
  base_url + "/1234567:detectIntent", {

		    method: 'POST',	
			
			headers: {
				"Accept": "application/json, text/plain, */*",
                "Content-Type": "application/json",

                "Authorization": "Bearer " + token,

            },

			
            body: JSON.stringify(input_data)

        });
		
		
	 const data = await response.json();
	// console.log(data);
	 console.log("result: ", data.queryResult.fulfillmentText);
	 speak(data.queryResult.fulfillmentText);
};	
	// 
let inputText = document.querySelector("#inputText");
const button = document.getElementById("button");
var listening= false;
var speaking= false;
const result = document.getElementById("result");
const main = document.getElementsByTagName("main")[0];  //-------
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
		  
const start = () => {
      if (!listening) {	
	  recognition.start();};
	listening = true;
	button.textContent = "Stop listening";
		 };		  
		  
const stop = () => {
		listening = false;
        recognition.stop();
        button.textContent = "Start listening";
         };



recognition.onend = function() {
		console.log('Speech recognition service end');
		listening = false;
		button.textContent = "Start listening";
		if (speaking == false) {
			startListening();
			}
		}
			
const onResult = event => {
        inputText.innerHTML = "";
        for (const res of event.results) {
             const text = document.createTextNode(res[0].transcript);
			 recogitionText =res[0].transcript;
             if (res.isFinal) {
                inputText.innerHTML = recogitionText;
              }

            }
		sendRecogitionText(recogitionText);
          };
		  
recognition.continuous = false;
          //recognition.interimResults = false; //True is the same result, why?
recognition.addEventListener("result", onResult);

button.addEventListener("click", event => {
            listening ? stop() : start();
            listening = !listening;
          });
		
if (typeof SpeechRecognition == "undefined") {
    button.remove();
    inputText.innerHTML = "The browser does not support speech recognition.";
        }   		

	  //////  

	var recogitionText ="";

	const sendRecogitionText = (order) => {
	console.log("function get order:" + order);
	//go to Dialogflow:
	//	 
	let query =order;
	let query_data = {"queryInput": {"text": {"text":query,"languageCode":"en-US"}}};
	console.log("query:" + query_data );
	queryDialog(query_data);
	}
	
const speak = message => {
  const msg = new SpeechSynthesisUtterance(message)
  msg.lang = 'en-US';
  var voices = window.speechSynthesis.getVoices();
  msg.voice = voices[4];
  msg.pitch = 1;
  speaking = true;
  window.speechSynthesis.speak(msg);
  
  msg.onstart = function(event) {
  setTimeout(function(){ 
  lipsPath.style.animationIterationCount = "infinite" }, 200); 
  }
  
  msg.onend = function(event) {
  lipsPath.style.animationIterationCount = "0";  // stop lips' moving.
  speaking = false;
  console.log('msg has finished being spoken after ' + event.elapsedTime + ' milliseconds.');
  if (listening == false) {
	startListening();
	}
  }
}
//speak("welcome");//
function startListening() {
  listening= true;
  recognition.start();
  button.textContent = "Stop listening";
  }

//var lipsPath;

	  
function startAnimation(){
// tempDIV =  document.querySelector(".custom-class");
// leftEye =  tempDIV.querySelector("svg");
// console.log("eye" + leftEye );
const face = document.querySelector("#face");
const upperFace = document.querySelector("#upperFace");
const lowerFace = document.querySelector("#lowerFace");
//divFace = document.createElement('div');
		  //divFace.style = "postion: absolute; left: 0%; width: 100%;";
//document.body.appendChild(divFace);

const lowerFaceSVG =  lowerFace.querySelector("svg");
lipsPath = lowerFaceSVG.querySelector('#lipsPath')
console.log("lipsPath:" + lipsPath);
///////
//////
lipsPath.classList.add("movingLips");

};


  </script>

  </body>
</html>